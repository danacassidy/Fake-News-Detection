# Fake-News-Detection

The purpose of this notebook is to use Natural Language Processing to train a model to tell the difference between "fake" and "real" news.
The model uses AP style, a set of writing guidelines that journalists abide by, to base its determinations on whether or not an article is "real" or "fake." This model performed with 99% accuracy based on the data given.

The topic of "fake" versus "real" news is one that's become more pressing as social media continues to evolve and information is more rapidly spread. The concept of news itself is not new and is a fundamental aspect of modern-day democracies. Journalists work to hold powerful entities and figures accountable and are supposed to be an ally of the people. Yet, distrust of the media is extremely common due to the nature of present-day society and officials constantly calling the media into question. Harmful conspiracies and propaganda aren't new but now have a platform to thrive and be spread among social sites. Companies and people are able to mask "pink slime," or garbage-level information, as quality journalism. This is a problem, as most people aren't entirely media literate and can't tell the difference -- but a computer can.
Table of Contents
1. Importing libraries and data
2. Data cleaning
3. Feature Extraction
4. Training the model
5. Analyzing and exploring some more
6. Conclusion + takeaways

This model allowed me to use my background as a journalist to better understand why it performed the way it did. 
Data from Kaggle: https://www.kaggle.com/danacassidy/fake-news-detector-nlp/edit

